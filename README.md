# BUAA-awesome-PTM

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A curated list of resources for self-supervised pre-trained models (PTM), especially in attack and defense.

## contents列表

### 模型架构 (Architecture)
#### 1. NLP (Natural Language Processing)

* #####  [Bert: Pre-training of deep bidirectional transformers for language understanding](https://arxiv.org/abs/1810.04805)
* #####  [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692)

#### 2. CV （Computer Vision)

* ##### [Moco:Momentum Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/abs/1911.05722)
* ##### [SimCLR:A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/abs/2002.05709?ref=hackernoon.com)

#### 3. Speech (Speech)

* ##### [SpeechBERT: An Audio-and-text Jointly Learned Language Model for End-to-end Spoken Question Answering](https://arxiv.org/abs/1910.11559)


### 开源代码、工具、平台(Open Source Code & Tools & Platform)

 * ##### 1. 🤗 [HuggingFace's Transformers: State-of-the-art Natural Language Processing](https://github.com/huggingface/transformers) by Huggingface Co. BERT家族的pytorch封装
 * ##### 2. [fairseq: A Fast, Extensible Toolkit for Sequence Modeling](https://github.com/pytorch/fairseq) by FaceBook， 预训练的序列模型的pytorch实现

### 攻击方法 ( Attack Method)

* ##### 1. [TextFooler：Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment](https://arxiv.org/abs/1907.11932)
* ##### 2. [Extracting Training Data from Large Language Models](https://arxiv.org/abs/2012.07805)
* ##### 3. [Membership Inference Attacks against Machine Learning Models](https://arxiv.org/abs/1610.05820)
* ##### 4. [BERT-ATTACK: Adversarial Attack Against BERT Using BERT](https://arxiv.org/abs/2004.09984)

### 防御方法 (Defend Method)

* ##### 1. [TextHide: Tackling Data Privacy in Language Understanding Tasks](https://arxiv.org/abs/2010.06053v1)

### 漏洞报道 (Defeacts Report)

* ##### 1. [Privacy Considerations in Large Language Models](https://ai.googleblog.com/2020/12/privacy-considerations-in-large.html)
* ##### 2. [GPT3之语言垃圾](https://mp.weixin.qq.com/s/NWPWc2xPTeXM75O949-ziw)


